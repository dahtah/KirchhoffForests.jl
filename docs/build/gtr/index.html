<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>RSF-based Graph Tikhonov Regularization · KirchoffForests.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">KirchoffForests.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">KirchoffForests.jl: a Julia package for Random Forests on Graphs, and Applications</a></li><li><a class="tocitem" href="../rsf/">What&#39;s an RSF?</a></li><li class="is-active"><a class="tocitem" href>RSF-based Graph Tikhonov Regularization</a><ul class="internal"><li><a class="tocitem" href="#Variance-reduction-on-\\tilde{\\mathbf{x}}"><span>Variance reduction on <span>$\tilde{\mathbf{x}}$</span></span></a></li><li><a class="tocitem" href="#Some-other-applications"><span>Some other applications</span></a></li></ul></li><li><a class="tocitem" href="../trace/">Trace Estimation</a></li><li><a class="tocitem" href="../typesandfunc/">Types and Functions</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>RSF-based Graph Tikhonov Regularization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>RSF-based Graph Tikhonov Regularization</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dahtah/KirchoffForests.jl/blob/master/docs/src/gtr.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Graph-signal-smoothing-and-interpolation"><a class="docs-heading-anchor" href="#Graph-signal-smoothing-and-interpolation">Graph signal smoothing and interpolation</a><a id="Graph-signal-smoothing-and-interpolation-1"></a><a class="docs-heading-anchor-permalink" href="#Graph-signal-smoothing-and-interpolation" title="Permalink"></a></h1><p>Signal denoising (i.e. eliminating noisy components in the signal) and impainting (i.e. completing) are two well-known problems in classical signal processing. In the case of graph signals (i.e. signals that are defined over the vertices), various approaches aim to output a solution that is a smooth signal (i.e. not highly varying through the edges) over the underlying graph structure.  </p><p>Graph Tikhonov regularization is one of these approaches that generically formulates the problem:</p><div class="admonition is-info"><header class="admonition-header">Graph Tikhonov regularization</header><div class="admonition-body"><p>Given a graph <span>$\mathcal{G}=(\mathcal{V},\mathcal{E},w)$</span>, assume we have <span>$p&lt;|\mathcal{V}|$</span> noisy measurements <span>$\mathbf{y}=[y_1,\dots,y_p]^\top$</span> over the vertices. We would like to obtain a smooth and complete signal over the vertices by solving:</p><p class="math-container">\[\hat{\mathbf{x}} = \arg\min_{\mathbf{x} \in \mathbb{R}^n} \underbrace{|| \mathsf{M}\mathbf{y} - \mathbf{x} ||^2_\mathsf{Q}}_{{\text{Fidelity}}} +\underbrace{ \mathbf{x}^T\mathsf{L}\mathbf{x}}_{\text{Regularization}},\]</p><p>where <span>$\mathsf{M}\in\mathbb{R}^{n\times p}$</span> is a partial identity matrix, <span>$\mathsf{Q}=\text{diag}(q_1,\dots,q_n)$</span> contains the pointwise regularization parameters, <span>$\mathsf{L} $ is the graph Laplacian and $\mathbf{x}^T\mathsf{L}\mathbf{x}  = \sum\limits_{(i,j)\in\mathcal{E}}w(i,j)(x_i-x_j)^2$</span>. The closed-form solution to this formulation is:</p><p class="math-container">\[    \hat{\mathbf{x}}  = \mathsf{K}\mathbf{y}&#39;,\]</p><p>with <span>$\mathsf{K}=(\mathsf{L} + \mathsf{Q})^{-1}\mathsf{Q}$</span> and <span>$\mathbf{y}= \mathsf{M}\mathbf{y}$</span>.</p></div></div><p>There is an unbiased estimator to estimate this matrix inverse via RSFs. This estimator, defined as <span>$\tilde{x}_i \coloneqq y&#39;_{r_{\Phi_Q}(i)}$</span>, operates as follows:</p><ul><li>Sample <span>$\Phi_Q$</span> by setting <span>$Q = (q_1, \dots,q_n)$</span>,</li><li>Then, within each tree of the sampled forest, propagate the measurement in the root.</li></ul><p>See <a href="../references/#pilavci2021graph">Yusuf Yiğit Pilavcı, Pierre-Olivier Amblard, Simon Barthelmé, Nicolas Tremblay (2021)</a> for more details.</p><p>This estimator can be called in KirchoffForests.jl as follows:</p><pre><code class="language- hljs">julia&gt; using KirchoffForests,Graphs,LinearAlgebra,Random,PyPlot

julia&gt; rng = MersenneTwister(12345); # Set random seed

julia&gt; g = Graphs.grid([4,4])
{16, 24} undirected simple Int64 graph

# Generate an incomplete signal
julia&gt; p = 8; n = nv(g); y= rand(rng, p); labelednodes = randperm(rng,n)[1:p]; M=I(n)[:,labelednodes];

julia&gt; yprime = M*y;

julia&gt; Q = rand(rng, n); # Set regularization parameters

julia&gt; rf = random_forest(g,Q,rng)
Random forest. Size of original graph 16.
Number of trees 4


julia&gt; xtilde = rf*yprime
16-element Array{Float64,1}:
0.0
0.0
0.0
0.0
0.8350140149860443
0.8350140149860443
0.8350140149860443
⋮
0.8350140149860443
0.8350140149860443
0.36580119057192695
0.8350140149860443
0.8350140149860443
0.36580119057192695
0.36580119057192695</code></pre><table><tr><th style="text-align: center">Input graph and signal <span>$\mathbf{y}&#39;$</span></th><th style="text-align: center">Sampled forest <code>rf</code></th><th style="text-align: center">The RSF estimator <span>$\tilde{\mathbf{x}}$</span></th></tr><tr><td style="text-align: center"><img src="../gtr-graph.svg" alt/></td><td style="text-align: center"><img src="../gtr-forest.svg" alt/></td><td style="text-align: center"><img src="../gtr-xtilde.svg" alt/></td></tr></table><h2 id="Variance-reduction-on-\\tilde{\\mathbf{x}}"><a class="docs-heading-anchor" href="#Variance-reduction-on-\\tilde{\\mathbf{x}}">Variance reduction on <span>$\tilde{\mathbf{x}}$</span></a><a id="Variance-reduction-on-\\tilde{\\mathbf{x}}-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-reduction-on-\\tilde{\\mathbf{x}}" title="Permalink"></a></h2><p>There are several ways to reduce the variance of <span>$\tilde{\mathbf{x}}$</span>:</p><p><strong>Conditional Monte Carlo</strong>: Thanks to the nice theoretical properties of RSFs, one can reduce the variance of <span>$\tilde{\mathbf{x}}$</span> by propagating the locally weighted averages within each tree instead of the measurement of the root:</p><p class="math-container">\[    \bar{x}_i = \frac{\sum\limits_{j\in\mathcal{V}_{t(i)}}q_j y&#39;_j}{\sum\limits_{k\in\mathcal{V}_{t(i)}}q_k}.\]</p><p>where <span>$\mathcal{V}_{t(i)}$</span> is the set of vertices of the tree in <span>$\Phi_Q$</span> which node <span>$i$</span> belongs to. See <a href="../references/#pilavci2021graph">Yusuf Yiğit Pilavcı, Pierre-Olivier Amblard, Simon Barthelmé, Nicolas Tremblay (2021)</a> for more details.</p><p>This new estimator <span>$\bar{\mathbf{x}}$</span> can be computed by using the structure called <a href="@ref"><code>Partition</code></a>:</p><pre><code class="language- hljs">julia&gt; p = Partition(rf)
Graph partition. Size of original graph 16.
Number of parts 4

# A bit elaborate way to compute the weighted average within each tree
julia&gt; xbar = (p*(yprime .* Q)) ./ (p*Q)
16-element Array{Float64,1}:
 0.1995397697360063
 0.1995397697360063
 0.1995397697360063
 0.1995397697360063
 0.29575020044545924
 0.29575020044545924
 ⋮
 0.29575020044545924
 0.07777354234714352
 0.29575020044545924
 0.29575020044545924
 0.07777354234714352
 0.07777354234714352</code></pre><table><tr><th style="text-align: center">The estimate by <span>$\tilde{\mathbf{x}}$</span></th><th style="text-align: center">The estimate by <span>$\bar{\mathbf{x}}$</span></th><th style="text-align: center">Exact Solution <span>$\hat{\mathbf{x}}$</span></th></tr><tr><td style="text-align: center"><img src="../gtr-xtilde.svg" alt/></td><td style="text-align: center"><img src="../gtr-xbar.svg" alt/></td><td style="text-align: center"><img src="../gtr-exact.svg" alt/></td></tr></table><p><strong>Control variate technique</strong>: Another technique to reduce the variance/expected error is the control variate technique which defines the following estimator:</p><p class="math-container">\[\bar{\mathbf{z}} \coloneqq \bar{\mathbf{x}} - \alpha(\mathsf{K}^{-1}\bar{\mathbf{x}} - \mathbf{y}&#39;),\]</p><p>where <span>$\alpha$</span> is a hyperparameter which is easy to choose as described in <a href="../references/#pilavci2021variance">Yusuf Yiğit Pilavcı, Pierre-Olivier Amblard, Simon Barthelmé, Nicolas Tremblay (2021)</a>.   </p><pre><code class="language- hljs">julia&gt; L = laplacian_matrix(g);

julia&gt; α = 2*minimum(Q)/(minimum(Q)+maximum(degree(g))) # Chosen as suggested
0.009474493197967612

julia&gt; zbar = xbar - α*((L * xbar) ./ Q + xbar  - yprime)
16-element Array{Float64,1}:
 0.20359013809375195
 0.25085798950864824
 0.1999698865149873
 0.19439266976895148
 0.29449512115874615
 0.2912856157260843
 ⋮
 0.28991581536522015
 0.0791621243376845
 0.2929481171830412
 0.29329844131810934
 0.0907881208925323
 0.07703667744919367</code></pre><table><tr><th style="text-align: center">The estimate by <span>$\bar{\mathbf{x}}$</span></th><th style="text-align: center">The estimate by <span>$\bar{\mathbf{z}}$</span></th><th style="text-align: center">Exact Solution <span>$\hat{\mathbf{x}}$</span></th></tr><tr><td style="text-align: center"><img src="../gtr-xbar.svg" alt/></td><td style="text-align: center"><img src="../gtr-zbar.svg" alt/></td><td style="text-align: center"><img src="../gtr-exact.svg" alt/></td></tr></table><h2 id="Some-other-applications"><a class="docs-heading-anchor" href="#Some-other-applications">Some other applications</a><a id="Some-other-applications-1"></a><a class="docs-heading-anchor-permalink" href="#Some-other-applications" title="Permalink"></a></h2><p>We find some applications of these estimators in certain graph-based optimization problems: </p><ul><li>Solving Edge-LASSO via ADMM. <a href="https://gricad-gitlab.univ-grenoble-alpes.fr/barthesi/RandomForests.jl/-/blob/docs/docs/src/notebooks/Edge%20Lasso-%20ADMM/Edge%20Lasso-%20ADMM.md">Notebook</a></li><li>Newton&#39;s method for Poisson noise <a href="https://gricad-gitlab.univ-grenoble-alpes.fr/barthesi/RandomForests.jl/-/blob/docs/docs/src/notebooks/Newton&#39;s%20method%20for%20Poisson%20noise/Newton&#39;s%20method%20for%20Poisson%20noise.md">Notebook</a></li></ul><p>More explanations and examples are in the notebooks. </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../rsf/">« What&#39;s an RSF?</a><a class="docs-footer-nextpage" href="../trace/">Trace Estimation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 26 May 2024 21:39">Sunday 26 May 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
