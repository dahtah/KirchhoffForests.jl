<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>ADMM for Edge LASSO · KirchoffForests.jl</title><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">KirchoffForests.jl</a></span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">KirchoffForests.jl: a Julia package for Random Forests on Graphs, and Applications</a></li><li><a class="tocitem" href="../../../rsf/">What&#39;s an RSF?</a></li><li><a class="tocitem" href="../../../gtr/">RSF-based Graph Tikhonov Regularization</a></li><li><a class="tocitem" href="../../../trace/">Trace Estimation</a></li><li><a class="tocitem" href="../../../typesandfunc/">Types and Functions</a></li><li><a class="tocitem" href="../../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>ADMM for Edge LASSO</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>ADMM for Edge LASSO</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dahtah/KirchoffForests.jl/blob/master/docs/src/notebooks/Edge Lasso- ADMM/Edge Lasso- ADMM.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ADMM-for-Edge-LASSO"><a class="docs-heading-anchor" href="#ADMM-for-Edge-LASSO">ADMM for Edge LASSO</a><a id="ADMM-for-Edge-LASSO-1"></a><a class="docs-heading-anchor-permalink" href="#ADMM-for-Edge-LASSO" title="Permalink"></a></h1><p>The edge- LASSO (Least Absolute Shrinkage and Selection Operator) problem corresponds to <span>$L_1$</span> regularization on graphs. The solution in this case is a sparse and smooth signal on the graph. It is formulated in the following way:  $ 	\mathbf{x}^\star = \arg\min<em>{\mathbf{x}\in\mathbb{R}^n} \frac{q}{2}||\mathbf{x} - \mathbf{y}||</em>2^2 + || \mathsf{B}\mathbf{x} ||<em>1, $ where <span>$\mathsf{B}\in\mathbb{R}^{m\times n}$</span> is the edge-incidence matrix that takes the following form:  $     \mathsf{B}</em>{i,k} = \begin{cases}         - w(i,j) &amp; i&lt; j \text{ and } e<em>k=(i,j)\in\mathcal{E} \
        w(i,j) &amp; i&gt; j  \text{ and } e</em>k=(i,j)\in\mathcal{E} \          0 &amp; \text{otherwise}     \end{cases}. $ In other words, <span>$\mathsf{B}\mathbf{x}$</span> computes the gradients of the signal <span>$\mathbf{x}$</span> over the edges. Then, by taking the <span>$L_1$</span> norm of this vector, one has the total absolute gradient of <span>$\mathbf{x}$</span>. As aforementioned, minimization over this regularization cost yields a sparse and smooth signal. </p><pre><code class="language-julia hljs">using KirchoffForests
using Graphs
using StatsBase
using Distributions
using SparseArrays
using LinearAlgebra
using PoissonRandom
using PyPlot</code></pre><pre><code class="language-julia hljs">using TestImages, ImageQualityIndexes,Images</code></pre><pre><code class="language-julia hljs">imname = &quot;house&quot;
image = imresize(testimage(imname), 128, 128)
image = Float64.(Gray.(image))
nx = size(image,1)
ny = size(image,2)
rs = (v) -&gt; reshape(v,nx,ny)
G = Graphs.grid([nx,ny])
image = image[:]
nrep = 20

σ = 0.2
mu = 5.0</code></pre><pre><code class="nohighlight hljs">5.0</code></pre><pre><code class="language-julia hljs">im_noisy = image .+ randn(length(image))*σ;</code></pre><h2 id="Denoising-Gaussian-noise-via-ADMM-."><a class="docs-heading-anchor" href="#Denoising-Gaussian-noise-via-ADMM-.">Denoising Gaussian noise via ADMM .</a><a id="Denoising-Gaussian-noise-via-ADMM-.-1"></a><a class="docs-heading-anchor-permalink" href="#Denoising-Gaussian-noise-via-ADMM-." title="Permalink"></a></h2><p>In this example, we consider an image denoising application where the noise is assumed to be additive Gaussian noise:  $     \mathbf{y} = \mathbf{x} + \mathbf{\epsilon}, \quad \forall i \in \mathcal{V}, \epsilon<em>i \sim\mathcal{N}(\mathbf{0},\mathsf{I})  $ Then, for the problem above, one can approximate the solution by using the method of ADMM. This method iteratively solves the problem at hand by running the iterative steps:  $ \begin{split} 	\mathbf{x}</em>{k+1} &amp;= \arg\min<em>{\mathbf{x} \in\mathbb{R}^n}\left(\frac{q}{2}||\mathbf{x}-\mathbf{y}||</em>2^2 + \frac{\rho}{2}||\mathsf{B}\mathbf{x} -\mathbf{z}<em>{k}+\mathbf{u}</em>{k}||<em>2^2\right) \
	\mathbf{z}</em>{k+1} &amp;= \arg\min<em>{\mathbf{z} \in\mathbb{R}^m}\left(||\mathbf{z}||</em>1 + \frac{\rho}{2}||\mathsf{B}\mathbf{x}<em>{k+1} -\mathbf{z}+\mathbf{u}</em>{k}||<em>2^2 \right) \
	\mathbf{u}</em>{k+1} &amp;= \mathbf{u}<em>k + (\mathsf{B}\mathbf{x}^{k+1} - \mathbf{z}^{k+1}). \
\end{split} $ The parameters \mathbf{x}</em>k<span>$, $\mathbf{y}_k$</span> and <span>$\mathbf{u}_k$</span> are arbitrarily initialized and are updated at every step, and <span>$\rho$</span> is a user-defined parameter. Here, the computationally heavy part is the first step in which one needs to compute this inverse:  $     \mathbf{x}<em>{k+1} = (q\mathsf{I} + \rho\mathsf{L})^{-1}(q\mathbf{y} + \rho\mathsf{B}^{\top}\mathbf{z}</em>k - \rho\mathsf{B}^\top\mathbf{u}_k). $ Notice that one can see this inverse as the regularized inverse of <span>$\mathsf{L}$</span>, thus it can be approximated via forest-based estimators. Moreover, the updated part through iterations is not the inverse but the vector that the inverted matrix is multiplied with. This allows us to sample spanning forests once and use them for every iterations. This idea has not implemented yet, so the following function implements ADMM with the exact and forest based updates while forests are sampled at every iterations.  </p><pre><code class="language-julia hljs">@elapsed xadmm_exact,loss_func_exact= admm_edge_lasso(G,mu,im_noisy;maxiter=200,ρ=0.2,method=&quot;exact&quot;)</code></pre><pre><code class="nohighlight hljs">25.171844969</code></pre><pre><code class="language-julia hljs">@elapsed xadmm_forest,loss_func_forest= admm_edge_lasso(G,mu,im_noisy;maxiter=200,ρ=0.2,method=&quot;xbar&quot;,Nfor=3)</code></pre><pre><code class="nohighlight hljs">4.580849309</code></pre><pre><code class="language-julia hljs">xadmm_exact= rs(xadmm_exact)
xadmm_forest= rs(xadmm_forest);</code></pre><p>Both qualitative and quantitative result shows that forest-based updates empirically converges the solution computed by the exact updates while taking much less time. Moreover, the sparse (almost piece-wise constant) structure of the solution is clearly visible on these image examples.</p><pre><code class="language-julia hljs">figure(figsize=[15,4])
subplot(1,4,1)
title(&quot;Original Image&quot;)
imshow(rs(image),cmap=&quot;gray&quot;)
axis(&quot;off&quot;)
subplot(1,4,2)
title(&quot;Noisy Image&quot;)
imshow(rs(im_noisy),cmap=&quot;gray&quot;)
axis(&quot;off&quot;)
subplot(1,4,3)
title(&quot;Solution by Exact Updates&quot;)
imshow(xadmm_exact,cmap=&quot;gray&quot;)
axis(&quot;off&quot;)
subplot(1,4,4)
title(&quot;Solution by Forest Updates &quot;)
imshow(rs(xadmm_forest),cmap=&quot;gray&quot;)
axis(&quot;off&quot;)
</code></pre><p><img src="../output_10_0.png" alt="png"/></p><pre><code class="nohighlight hljs">(-0.5, 127.5, 127.5, -0.5)</code></pre><pre><code class="language-julia hljs">y = rs(im_noisy)
noisy_psnr = (ImageQualityIndexes.assess_psnr(y, image))
xadmm_exact_psnr = (ImageQualityIndexes.assess_psnr(xadmm_exact, image))
xforest_psnr = (ImageQualityIndexes.assess_psnr(xadmm_forest, image))

display(&quot;y psnr: $noisy_psnr&quot;)
display(&quot;xadmm_exact psnr: $xadmm_exact_psnr&quot;)
display(&quot;xforest psnr : $xforest_psnr&quot;)</code></pre><pre><code class="nohighlight hljs">&quot;y psnr: 13.972511184499886&quot;



&quot;xadmm_exact psnr: 23.860703046152313&quot;



&quot;xforest psnr : 23.816177942582524&quot;</code></pre><pre><code class="language-julia hljs">fig = figure(figsize=[5,5])
plot((1:length(loss_func_exact)), loss_func_exact, color=&quot;black&quot;,linewidth=6.0, label=string(&quot;Updates with &quot;, latexstring(&quot;\$\\hat{x}\$&quot;)))
plot((1:length(loss_func_forest)), loss_func_forest, color=&quot;orange&quot;,linewidth=6.0,linestyle=&quot;--&quot;, label=string(&quot;Updates with &quot;, latexstring(&quot;\$\\bar{x}\$&quot;)))
xlabel(&quot;Iterations&quot;,fontsize=20)
ylabel(&quot;Loss Function&quot;,fontsize=20)
xticks(fontsize=15)
yticks(fontsize=15)
PyPlot.grid(true)
tight_layout()
legend(fontsize=15)
</code></pre><p><img src="../output_12_0.png" alt="png"/></p><pre><code class="nohighlight hljs">PyObject &lt;matplotlib.legend.Legend object at 0x7f5b5004c460&gt;</code></pre></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 26 May 2024 21:39">Sunday 26 May 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
